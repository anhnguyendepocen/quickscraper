% Generated by roxygen2 (4.0.1): do not edit by hand
\name{scrape}
\alias{scrape}
\title{Scrape data from web pages}
\usage{
scrape(urls, url_file = NULL, ratelimit = 3, scraper = "generic_open",
  outdir = NULL, results = c("load", "save", "both"), args = list())
}
\arguments{
\item{urls}{A vector of URLs to scrape}

\item{url_file}{Alternatively, a file containing a list or URLs separated by
newlines}

\item{scraper}{A single scraper to use, or list of scrapers the same length
as \code{urls}.  If \code{NULL}, \code{scrape} will choose scrapers based on
the domains of URLs.  The scraper can either be one of the included scrapers
(found with \code{names(quickscraper:::package_scrapers)}), the path to a
scraperJSON file, or a scraperJSON file converted to an R list.}

\item{list}{The form to return results in, either "list", "data.frame", or
"none" to only retain results as JSON files on disk}

\item{outdir}{The directory to write results to.  If NULL, files will be
written to a temporary directory.}

\item{results}{Save the downloaded results? If "load", \code{scrape} will
return the results as a list.  If "save", the results will be saved in
\code{outdir}. If "both", both.}
}
\description{
Take a vector of URLs and scrape data from the associated web pages, using
\code{quickscrape}
}

